{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.signal as signal\n",
    "import pywt\n",
    "import wfdb\n",
    "import peakutils\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(data):\n",
    "    lowpass = 200\n",
    "    highpass = 0.5\n",
    "    \n",
    "    \n",
    "    scalar = MinMaxScaler((-1,1))\n",
    "    data = scalar.fit_transform(data)\n",
    "    data.resize(len(data))\n",
    "    \n",
    "\n",
    "    a,b = signal.butter(6,(highpass,lowpass), btype='bandpass', analog=True)\n",
    "    filtered = signal.lfilter(b,a,data)\n",
    "    smoothed = signal.cspline1d(filtered, lamb=1000)\n",
    "    \n",
    "    return smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRPeaks(smoothed):\n",
    "    signal_slice = np.ndarray.flatten(smoothed)\n",
    "    rPeaks = peakutils.indexes(signal_slice, thres=0.3, min_dist=200)\n",
    "    return rPeaks.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findTPeaks(smoothed, peak1, peak2):\n",
    "\n",
    "    \n",
    "    signal_slice = smoothed[peak1+20:peak1+140]\n",
    "    t = peakutils.indexes(signal_slice, thres=0.2, min_dist=200)\n",
    "\n",
    "    \n",
    "    return t + peak1 + 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPPeaks(smoothed, peak1, peak2):\n",
    "    pPeaks = []\n",
    "\n",
    "    signal_slice = smoothed[peak2-90:peak2-20]\n",
    "    p = peakutils.indexes(signal_slice, thres=0.2, min_dist=200)\n",
    "            \n",
    "\n",
    "    \n",
    "    return peak2 - 90 + p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findQRSarea(smoothed, peak):\n",
    "    \n",
    "    left_x = peak\n",
    "    right_x = peak\n",
    "    top_x = peak\n",
    "    \n",
    "    for i in range (1,200):\n",
    "        if (smoothed[peak-i]>smoothed[peak-i+1]): left_x = peak-i +1\n",
    "        if (smoothed[peak+i]>smoothed[peak+i-1]): right_x = peak+i-1\n",
    "            \n",
    "    left_y = smoothed[left_x]\n",
    "    right_y = smoothed[right_x]\n",
    "    top_y = smoothed[peak]\n",
    "    \n",
    "    area = 0.5*abs(left_x*(top_y-right_y)+ top_x*(right_y-left_y)+ right_x*(left_y-top_y))\n",
    "    \n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(smoothed, rPeaks, x):\n",
    "    data = []\n",
    "    interval = []\n",
    "\n",
    "\n",
    "    for i in range(1,len(rPeaks)-2):\n",
    "\n",
    "        \n",
    "\n",
    "        tpeak = findTPeaks(smoothed, rPeaks[i], rPeaks[i+1])\n",
    "        ppeak = findPPeaks(smoothed, rPeaks[i], rPeaks[i+1])\n",
    "        \n",
    "        RR_dist = rPeaks[i+1]-rPeaks[i]\n",
    "        RR_mean = (smoothed[rPeaks[i]]+ smoothed[rPeaks[i+1]])/2\n",
    "        QRSarea = findQRSarea(smoothed,rPeaks[i])\n",
    "        \n",
    "        if x in range(100,200):\n",
    "            label = 0\n",
    "        elif x in range(200,300):\n",
    "            label = 1\n",
    "        \n",
    "\n",
    "        \n",
    "        if len(tpeak) == 0 and len(ppeak) == 0:\n",
    "            data.append([RR_dist,RR_mean,-1,-1,-1,-1,-1,QRSarea,0,0,label])\n",
    "            continue\n",
    "            \n",
    "        elif len(tpeak) == 0:\n",
    "            ppeak = ppeak[0]\n",
    "            \n",
    "\n",
    "            \n",
    "            PRb_dist = ppeak - rPeaks[i]\n",
    "            PRa_dist = rPeaks[i+1] - ppeak\n",
    "            PRb_PRa_ratio = PRb_dist/PRa_dist\n",
    "            P_amp = smoothed[ppeak]\n",
    "            \n",
    "            data.append([RR_dist,RR_mean,-1,-1,PRb_PRa_ratio,-1,P_amp,QRSarea,1,0,label])\n",
    "            continue\n",
    "        else:\n",
    "            tpeak = tpeak[0]\n",
    "            \n",
    "        if len(ppeak) == 0:\n",
    "            \n",
    "            TRb_dist = tpeak - rPeaks[i]\n",
    "            TRa_dist = rPeaks[i+1] - tpeak\n",
    "            TRb_TRa_ratio = TRb_dist/TRa_dist\n",
    "            T_amp = smoothed[tpeak]\n",
    "            \n",
    "            data.append([RR_dist,RR_mean,-1,TRb_TRa_ratio,-1,T_amp,-1,QRSarea,0,1,label])\n",
    "            continue\n",
    "        else:\n",
    "            ppeak = ppeak[0]\n",
    "        \n",
    "        RR_dist = rPeaks[i+1]-rPeaks[i]\n",
    "        RR_mean = (smoothed[rPeaks[i]]+ smoothed[rPeaks[i+1]])/2\n",
    "        \n",
    "        \n",
    "        PT_dist = tpeak-ppeak\n",
    "        \n",
    "        TRb_dist = tpeak - rPeaks[i]\n",
    "        TRa_dist = rPeaks[i+1] - tpeak\n",
    "        TRb_TRa_ratio = TRb_dist/TRa_dist\n",
    "        \n",
    "        PRb_dist = ppeak - rPeaks[i]\n",
    "        PRa_dist = rPeaks[i+1] - ppeak\n",
    "        PRb_PRa_ratio = PRb_dist/PRa_dist\n",
    "        \n",
    "        T_amp = smoothed[tpeak]\n",
    "        P_amp = smoothed[ppeak]\n",
    "        \n",
    "        \n",
    "        \n",
    "        interval = []\n",
    "        interval.append(RR_dist)\n",
    "        interval.append(RR_mean)\n",
    "        interval.append(PT_dist)\n",
    "        interval.append(TRb_TRa_ratio)\n",
    "        interval.append(PRb_PRa_ratio)\n",
    "        interval.append(T_amp)\n",
    "        interval.append(P_amp)\n",
    "        interval.append(QRSarea)\n",
    "        interval.append(1)\n",
    "        interval.append(1)\n",
    "        interval.append(label)\n",
    "\n",
    "        \n",
    "        data.append(interval)\n",
    "        \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleID = []\n",
    "\n",
    "for i in range(100,125):\n",
    "    if i not in [102,104,110,120, 122,111,107]:\n",
    "        sampleID.append(i)\n",
    "\n",
    "for i in range(200,235):\n",
    "    if i not in [204,206,211,216,218,224,225,226,227,229, 234,210,217]:\n",
    "        sampleID.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [122,111,107,234,210,217]\n",
    "len(sampleID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "groups = []\n",
    "for i in range(8):\n",
    "    group = []\n",
    "    for i in range(5):\n",
    "        num = random.randrange(len(sampleID))\n",
    "        group.append(sampleID[num])\n",
    "        sampleID.remove(sampleID[num])\n",
    "    groups.append(group)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups.extend([test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[223, 103, 221, 106, 200],\n",
       " [105, 220, 203, 202, 222],\n",
       " [116, 208, 205, 124, 213],\n",
       " [231, 118, 101, 201, 233],\n",
       " [114, 214, 115, 228, 123],\n",
       " [230, 109, 113, 219, 121],\n",
       " [112, 117, 207, 212, 232],\n",
       " [119, 209, 108, 215, 100],\n",
       " [122, 111, 107, 234, 210, 217]]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 1/9\n",
      "Done 2/9\n",
      "Done 3/9\n",
      "Done 4/9\n",
      "Done 5/9\n",
      "Done 6/9\n",
      "Done 7/9\n",
      "Done 8/9\n",
      "Done 9/9\n"
     ]
    }
   ],
   "source": [
    "for idx,group in enumerate(groups):\n",
    "    augmented = []\n",
    "\n",
    "    for i in group: \n",
    "\n",
    "        record = wfdb.rdsamp('mit-bih-arrhythmia-database-1.0-2.0/' + str(i))\n",
    "        ch = [record[1]['sig_name'].index('MLII')]\n",
    "        record = wfdb.rdsamp('mit-bih-arrhythmia-database-1.0-2.0/' + str(i), channels = ch)\n",
    "        data = record[0]\n",
    "        data = data.astype(np.float32)\n",
    "        #data.resize(len(data))\n",
    "\n",
    "        smoothed = smooth(data)\n",
    "\n",
    "        rPeaks = findRPeaks(smoothed)\n",
    "\n",
    "\n",
    "        aug_sample = augment(smoothed, rPeaks, i)\n",
    "\n",
    "        augmented.extend(aug_sample)\n",
    "\n",
    "        aug_sample = []\n",
    "    \n",
    "    augmented = np.array(augmented)\n",
    "    df = pd.DataFrame(augmented)\n",
    "    df.to_csv(\"group_3_{}.csv\".format(idx+1), index=False)\n",
    "    print(f\"Done {idx+1}/{9}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'groups' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-108dbcb2cd64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'groups' is not defined"
     ]
    }
   ],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented = np.array(augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"trainfoundfeature.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [[123,215,121,230,233], [221,101,114,232,207],[201,103,200,112,113],[117,220,119,231,209],[106,214,208,105,202],[212,213,219,100,115],[222,203,124,109,108],[205,116,118,228,223],[122,111,107,234,210,217]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
